{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-01-09T16:28:26.589399Z","iopub.execute_input":"2023-01-09T16:28:26.589748Z","iopub.status.idle":"2023-01-09T16:28:26.599741Z","shell.execute_reply.started":"2023-01-09T16:28:26.589718Z","shell.execute_reply":"2023-01-09T16:28:26.598497Z"},"trusted":true},"execution_count":178,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-aug-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-aug-2022/train.csv\n/kaggle/input/tabular-playground-series-aug-2022/test.csv\n/kaggle/input/pickle/model3.sav\n/kaggle/input/pickle/model1.sav\n/kaggle/input/pickle/model2.sav\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install feature-engine","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:56:12.336009Z","iopub.execute_input":"2023-01-09T17:56:12.336523Z","iopub.status.idle":"2023-01-09T17:56:26.687247Z","shell.execute_reply.started":"2023-01-09T17:56:12.336481Z","shell.execute_reply":"2023-01-09T17:56:26.685316Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!rm model1.sav model2.sav model3.sav","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:35.038675Z","iopub.execute_input":"2023-01-09T16:28:35.040073Z","iopub.status.idle":"2023-01-09T16:28:35.311322Z","shell.execute_reply.started":"2023-01-09T16:28:35.040025Z","shell.execute_reply":"2023-01-09T16:28:35.310006Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"#===============import===============#\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom sklearn.linear_model import LogisticRegression ,HuberRegressor\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.impute import KNNImputer\nfrom feature_engine.encoding import WoEEncoder\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\nTARGET = \"failure\"\n#usepickle=0","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:56:43.880666Z","iopub.execute_input":"2023-01-09T17:56:43.881118Z","iopub.status.idle":"2023-01-09T17:56:43.888993Z","shell.execute_reply.started":"2023-01-09T17:56:43.881084Z","shell.execute_reply":"2023-01-09T17:56:43.887681Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip freeze > requirements.txt","metadata":{"execution":{"iopub.status.busy":"2023-01-09T17:56:46.102127Z","iopub.execute_input":"2023-01-09T17:56:46.102595Z","iopub.status.idle":"2023-01-09T17:56:50.358796Z","shell.execute_reply.started":"2023-01-09T17:56:46.102557Z","shell.execute_reply":"2023-01-09T17:56:50.357362Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#===============load data===============#\ndef read(path):\n    data_dir = Path(path)\n    train = pd.read_csv(data_dir / \"train.csv\")\n    test = pd.read_csv(data_dir / \"test.csv\")\n    return train, test\n\ntrain, test = read(\"../input/tabular-playground-series-aug-2022\")\ntarget = train[\"failure\"]\ntrain.drop(\"failure\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:35.320871Z","iopub.execute_input":"2023-01-09T16:28:35.321299Z","iopub.status.idle":"2023-01-09T16:28:35.434517Z","shell.execute_reply.started":"2023-01-09T16:28:35.321274Z","shell.execute_reply":"2023-01-09T16:28:35.433647Z"},"trusted":true},"execution_count":182,"outputs":[]},{"cell_type":"code","source":"#===============preprocessing===============#\ndef preprocessing(df_train, df_test):\n    data = pd.concat([df_train, df_test])\n    data[\"m3_missing\"] = data[\"measurement_3\"].isnull().astype(np.int8)\n    data[\"m5_missing\"] = data[\"measurement_5\"].isnull().astype(np.int8)\n    feature = [f for f in df_test.columns if f.startswith(\"measurement\") or f == \"loading\"]\n\n    full = {}\n    full[\"measurement_17\"] = {\n        \"A\": [\"measurement_5\", \"measurement_6\", \"measurement_8\"],\n        \"B\": [\"measurement_4\", \"measurement_5\", \"measurement_7\"],\n        \"C\": [\"measurement_5\", \"measurement_7\", \"measurement_8\", \"measurement_9\"],\n        \"D\": [\"measurement_5\", \"measurement_6\", \"measurement_7\", \"measurement_8\"],\n        \"E\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_8\"],\n        \"F\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_7\"],\n        \"G\": [\"measurement_4\", \"measurement_6\", \"measurement_8\", \"measurement_9\"],\n        \"H\": [\"measurement_4\",\"measurement_5\",\"measurement_7\",\"measurement_8\",\"measurement_9\"],\n        \"I\": [\"measurement_3\", \"measurement_7\", \"measurement_8\"],\n    }\n\n    col = [col for col in df_test.columns if \"measurement\" not in col] + [\"loading\",\"m3_missing\",\"m5_missing\",]\n    a = []\n    b = []\n    for x in range(3, 17):\n        corr = np.absolute(data.drop(col, axis=1).corr()[f\"measurement_{x}\"]).sort_values(ascending=False)\n        a.append(np.round(np.sum(corr[1:4]), 3))  \n        b.append(f\"measurement_{x}\")\n    c = pd.DataFrame()\n    c[\"Selected columns\"] = b\n    c[\"correlation total\"] = a\n    c = c.sort_values(by=\"correlation total\", ascending=False).reset_index(drop=True)\n    #print(c.head(10))\n\n    for i in range(10):\n        m_col = (\"measurement_\" + c.iloc[i, 0][12:])  \n        fill_dict = {}\n        for x in data.product_code.unique():\n            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[m_col]).sort_values(ascending=False)\n            #print(corr)\n            m_col_dic = {}\n            m_col_dic[m_col] = corr[1:5].index.tolist()\n            fill_dict[x] = m_col_dic[m_col]\n        full[m_col] = fill_dict\n    feature = [f for f in data.columns if f.startswith(\"measurement\") or f == \"loading\"]\n    n_col = [col for col in df_train.columns if df_train[col].isnull().sum() != 0]\n    for code in data.product_code.unique():\n        for m_col in list(full.keys()):\n            tmp = data[data.product_code == code]\n            column = full[m_col][code]\n            ttrain = tmp[column + [m_col]].dropna(how=\"any\")\n            #print(tmp_train)\n            ttest = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp[m_col].isnull())]\n            #print(tmp_test)\n            model = HuberRegressor(epsilon=1.9,max_iter=3000)\n            model.fit(ttrain[column], ttrain[m_col])\n            data.loc[(data.product_code == code) & (data[column].isnull().sum(axis=1) == 0)& (data[m_col].isnull()),m_col,] = model.predict(ttest[column])\n\n        NA = data.loc[data[\"product_code\"] == code, n_col].isnull().sum().sum()\n        model1 = KNNImputer(n_neighbors=3)\n        data.loc[data.product_code == code, feature] = model1.fit_transform(data.loc[data.product_code == code, feature])\n\n    data[\"measurement_avg\"] = data[[f\"measurement_{i}\" for i in range(3, 17)]].mean(axis=1)\n    df_train = data.iloc[: df_train.shape[0], :]\n    df_test = data.iloc[df_train.shape[0] :, :]\n    #print(data)\n    #print(df_train)\n    #print(df_test)\n    woe_encoder = WoEEncoder(variables=[\"attribute_0\"])\n    woe_encoder.fit(df_train, target)\n    df_train = woe_encoder.transform(df_train)\n    df_test = woe_encoder.transform(df_test)\n    features = [\"loading\",\"attribute_0\",\"measurement_17\",\"measurement_0\",\"measurement_1\",\"measurement_2\",\"m3_missing\",\"m5_missing\",\"measurement_avg\"]\n    return df_train, df_test, features\n\ntrain, test, FEATURES = preprocessing(train, test)\ntrain[\"failure\"] = target","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:35.436028Z","iopub.execute_input":"2023-01-09T16:28:35.436362Z","iopub.status.idle":"2023-01-09T16:28:46.629845Z","shell.execute_reply.started":"2023-01-09T16:28:35.436331Z","shell.execute_reply":"2023-01-09T16:28:46.628835Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">3 vs 2 fold</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"#===============training===============#\ndef train_model(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    folds_dict = {f'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n               'Fold 3': [['A', 'C', 'E'], ['B', 'D']],\n               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n               'Fold 6': [['A', 'B', 'C'], ['D', 'E']],\n               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n               'Fold 10': [['B', 'C', 'E'], ['A', 'D']]} \n   \n    for fold in folds_dict.keys():\n        print(f'##### {fold} #####')\n        xtest = test.copy()\n        #print(df)\n        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n        #print(xtrain)\n        model = LogisticRegression(max_iter=200, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n        model.fit(xtrain,ytrain)\n        preds_valid = model.predict_proba(xvalid)[:, 1]\n        test_preds = model.predict_proba(xtest.values)[:, 1]\n        #print(test_preds)\n        #final_test_predictions.append(test_preds)\n        fold_score = roc_auc_score(yvalid, preds_valid)  \n        print(fold_score)\n    #final_test_predictions.append(test_preds)\n    return (model,final_test_predictions)\n\n#print(train)\nfilename = 'model1.sav'\n\n(model,final_test_preds) = train_model(train,test,FEATURES,TARGET)\npickle.dump(model, open(filename, 'wb'))\nfinal_test_preds.append(model.predict_proba(test[FEATURES].values)[:, 1])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:46.630935Z","iopub.execute_input":"2023-01-09T16:28:46.631153Z","iopub.status.idle":"2023-01-09T16:28:49.504837Z","shell.execute_reply.started":"2023-01-09T16:28:46.631132Z","shell.execute_reply":"2023-01-09T16:28:49.503966Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"##### Fold 1 #####\n0.590424659643622\n##### Fold 2 #####\n0.5870302712565572\n##### Fold 3 #####\n0.5952351775082422\n##### Fold 4 #####\n0.5870248450994079\n##### Fold 5 #####\n0.5891103224632019\n##### Fold 6 #####\n0.5890572383753485\n##### Fold 7 #####\n0.5858906328885832\n##### Fold 8 #####\n0.5899624327668974\n##### Fold 9 #####\n0.5843865344046771\n##### Fold 10 #####\n0.5958328959652958\n","output_type":"stream"}]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_df = test[[\"id\"]].copy().astype(int)\nsubmission_df[TARGET] = np.mean(np.column_stack(final_test_preds), axis=1)\nsubmission_df.to_csv(\"109550116submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:49.506192Z","iopub.execute_input":"2023-01-09T16:28:49.506741Z","iopub.status.idle":"2023-01-09T16:28:49.513731Z","shell.execute_reply.started":"2023-01-09T16:28:49.506707Z","shell.execute_reply":"2023-01-09T16:28:49.512969Z"},"trusted":true},"execution_count":185,"outputs":[{"execution_count":185,"output_type":"execute_result","data":{"text/plain":"'submission_df = test[[\"id\"]].copy().astype(int)\\nsubmission_df[TARGET] = np.mean(np.column_stack(final_test_preds), axis=1)\\nsubmission_df.to_csv(\"109550116submission.csv\", index=False)'"},"metadata":{}}]},{"cell_type":"markdown","source":" \n<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">K-fold</h1>\n</div>\n ","metadata":{}},{"cell_type":"code","source":"#===============training===============#\ndef train_model1(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    folds_dict = {f'Fold 1': [['B','C', 'D', 'E'], ['A']], \n               'Fold 2': [['A','B','D', 'E'], ['D']],\n               'Fold 3': [['A','B','C', 'D'], ['E']],\n               'Fold 4': [['A', 'B','D','E'], ['C']],\n               'Fold 5': [['A', 'D', 'C','E'], ['B']]} \n   \n    for fold in folds_dict.keys():\n        print(f'##### {fold} #####')\n        xtest = test.copy()\n        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n        #print(xtrain)\n        model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n        model.fit(xtrain,ytrain)\n        preds_valid = model.predict_proba(xvalid)[:, 1]\n        test_preds = model.predict_proba(xtest.values)[:, 1]\n        #print(test_preds)\n        final_test_predictions.append(test_preds)\n        fold_score = roc_auc_score(yvalid, preds_valid)  \n        print(fold_score)\n    return (model)\n\n#print(train)\n\nfilename = 'model2.sav'\n\n(model_kfold) = train_model1(train,test,FEATURES,TARGET)\npickle.dump(model_kfold, open(filename, 'wb'))\nfinal_test_preds1.append(model_kfold.predict_proba(test[FEATURES].values)[:, 1])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:49.516773Z","iopub.execute_input":"2023-01-09T16:28:49.519250Z","iopub.status.idle":"2023-01-09T16:28:51.185517Z","shell.execute_reply.started":"2023-01-09T16:28:49.519219Z","shell.execute_reply":"2023-01-09T16:28:51.184788Z"},"trusted":true},"execution_count":186,"outputs":[{"name":"stdout","text":"##### Fold 1 #####\n0.5916299060845487\n##### Fold 2 #####\n0.5988509442446043\n##### Fold 3 #####\n0.5819009833717517\n##### Fold 4 #####\n0.5852605096575232\n##### Fold 5 #####\n0.5924883658160595\n","output_type":"stream"}]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_kfold_df = test[[\"id\"]].copy().astype(int)\nsubmission_kfold_df[TARGET] = np.mean(np.column_stack(final_test_preds1), axis=1)\nsubmission_kfold_df.to_csv(\"109550116submission_kfold.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:51.188039Z","iopub.execute_input":"2023-01-09T16:28:51.188906Z","iopub.status.idle":"2023-01-09T16:28:51.193938Z","shell.execute_reply.started":"2023-01-09T16:28:51.188876Z","shell.execute_reply":"2023-01-09T16:28:51.193267Z"},"trusted":true},"execution_count":187,"outputs":[{"execution_count":187,"output_type":"execute_result","data":{"text/plain":"'submission_kfold_df = test[[\"id\"]].copy().astype(int)\\nsubmission_kfold_df[TARGET] = np.mean(np.column_stack(final_test_preds1), axis=1)\\nsubmission_kfold_df.to_csv(\"109550116submission_kfold.csv\", index=False)'"},"metadata":{}}]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">No-fold</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"#===============training===============#\ndef train_model2(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    \n    #print(f'########################## {fold} ##########################')\n    xtest = test.copy()\n    \n    xtrain, xvalid = train_test_split(df, random_state=777, train_size=0.8)\n    #print(xtrain)\n    ytrain = xtrain[TARGET]\n    #print(ytrain)\n    yvalid = xvalid[TARGET]\n    xtrain = xtrain[FEATURES]\n    xvalid = xvalid[FEATURES]\n    \n    model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n    model.fit(xtrain,ytrain)\n    preds_valid = model.predict_proba(xvalid)[:, 1]\n    test_preds = model.predict_proba(xtest.values)[:, 1]\n    #print(test_preds)\n    final_test_predictions.append(test_preds)\n    fold_score = roc_auc_score(yvalid, preds_valid)  \n    print(fold_score)\n    return (model,final_test_predictions)\n\n#print(train)\n#(model_no_fold,final_test_preds2) = train_model(train,test,FEATURES,TARGET)\n\nfilename = 'model3.sav'\n\n(model_no_fold,final_test_preds2) = train_model2(train,test,FEATURES,TARGET)\npickle.dump(model_no_fold, open(filename, 'wb'))\nfinal_test_preds2.append(model_no_fold.predict_proba(test[FEATURES].values)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:51.195268Z","iopub.execute_input":"2023-01-09T16:28:51.195782Z","iopub.status.idle":"2023-01-09T16:28:51.528287Z","shell.execute_reply.started":"2023-01-09T16:28:51.195754Z","shell.execute_reply":"2023-01-09T16:28:51.527575Z"},"trusted":true},"execution_count":188,"outputs":[{"name":"stdout","text":"0.5942057929074573\n","output_type":"stream"}]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_no_fold_df = test[[\"id\"]].copy().astype(int)\nsubmission_no_fold_df[TARGET] = np.mean(np.column_stack(final_test_preds2), axis=1)\nsubmission_no_fold_df.to_csv(\"109550116submission_no_fold.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:28:51.529618Z","iopub.execute_input":"2023-01-09T16:28:51.530114Z","iopub.status.idle":"2023-01-09T16:28:51.535103Z","shell.execute_reply.started":"2023-01-09T16:28:51.530086Z","shell.execute_reply":"2023-01-09T16:28:51.534410Z"},"trusted":true},"execution_count":189,"outputs":[{"execution_count":189,"output_type":"execute_result","data":{"text/plain":"'submission_no_fold_df = test[[\"id\"]].copy().astype(int)\\nsubmission_no_fold_df[TARGET] = np.mean(np.column_stack(final_test_preds2), axis=1)\\nsubmission_no_fold_df.to_csv(\"109550116submission_no_fold.csv\", index=False)'"},"metadata":{}}]}]}