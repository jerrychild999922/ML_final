{"cells":[{"cell_type":"code","execution_count":178,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-01-09T16:28:26.589748Z","iopub.status.busy":"2023-01-09T16:28:26.589399Z","iopub.status.idle":"2023-01-09T16:28:26.599741Z","shell.execute_reply":"2023-01-09T16:28:26.598497Z","shell.execute_reply.started":"2023-01-09T16:28:26.589718Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/tabular-playground-series-aug-2022/sample_submission.csv\n","/kaggle/input/tabular-playground-series-aug-2022/train.csv\n","/kaggle/input/tabular-playground-series-aug-2022/test.csv\n","/kaggle/input/pickle/model3.sav\n","/kaggle/input/pickle/model1.sav\n","/kaggle/input/pickle/model2.sav\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":179,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:26.603036Z","iopub.status.busy":"2023-01-09T16:28:26.602704Z","iopub.status.idle":"2023-01-09T16:28:35.036958Z","shell.execute_reply":"2023-01-09T16:28:35.035450Z","shell.execute_reply.started":"2023-01-09T16:28:26.603008Z"},"trusted":true},"outputs":[],"source":["%%capture\n","!pip install feature-engine"]},{"cell_type":"code","execution_count":180,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:35.040073Z","iopub.status.busy":"2023-01-09T16:28:35.038675Z","iopub.status.idle":"2023-01-09T16:28:35.311322Z","shell.execute_reply":"2023-01-09T16:28:35.310006Z","shell.execute_reply.started":"2023-01-09T16:28:35.040025Z"},"trusted":true},"outputs":[],"source":["!rm model1.sav model2.sav model3.sav"]},{"cell_type":"code","execution_count":181,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:35.313839Z","iopub.status.busy":"2023-01-09T16:28:35.313519Z","iopub.status.idle":"2023-01-09T16:28:35.319726Z","shell.execute_reply":"2023-01-09T16:28:35.318638Z","shell.execute_reply.started":"2023-01-09T16:28:35.313809Z"},"trusted":true},"outputs":[],"source":["#===============import===============#\n","import os\n","from pathlib import Path\n","import pandas as pd\n","import numpy as np\n","import pickle\n","from sklearn.linear_model import LogisticRegression ,HuberRegressor\n","from sklearn.metrics import roc_auc_score\n","from sklearn.impute import KNNImputer\n","from feature_engine.encoding import WoEEncoder\n","from sklearn.model_selection import train_test_split\n","import warnings\n","warnings.filterwarnings('ignore')\n","TARGET = \"failure\"\n","#usepickle=0"]},{"cell_type":"code","execution_count":182,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:35.321299Z","iopub.status.busy":"2023-01-09T16:28:35.320871Z","iopub.status.idle":"2023-01-09T16:28:35.434517Z","shell.execute_reply":"2023-01-09T16:28:35.433647Z","shell.execute_reply.started":"2023-01-09T16:28:35.321274Z"},"trusted":true},"outputs":[],"source":["#===============load data===============#\n","def read(path):\n","    data_dir = Path(path)\n","    train = pd.read_csv(data_dir / \"train.csv\")\n","    test = pd.read_csv(data_dir / \"test.csv\")\n","    return train, test\n","\n","train, test = read(\"../input/tabular-playground-series-aug-2022\")\n","target = train[\"failure\"]\n","train.drop(\"failure\", axis=1, inplace=True)"]},{"cell_type":"code","execution_count":183,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:35.436362Z","iopub.status.busy":"2023-01-09T16:28:35.436028Z","iopub.status.idle":"2023-01-09T16:28:46.629845Z","shell.execute_reply":"2023-01-09T16:28:46.628835Z","shell.execute_reply.started":"2023-01-09T16:28:35.436331Z"},"trusted":true},"outputs":[],"source":["#===============preprocessing===============#\n","def preprocessing(df_train, df_test):\n","    data = pd.concat([df_train, df_test])\n","    data[\"m3_missing\"] = data[\"measurement_3\"].isnull().astype(np.int8)\n","    data[\"m5_missing\"] = data[\"measurement_5\"].isnull().astype(np.int8)\n","    feature = [f for f in df_test.columns if f.startswith(\"measurement\") or f == \"loading\"]\n","\n","    full = {}\n","    full[\"measurement_17\"] = {\n","        \"A\": [\"measurement_5\", \"measurement_6\", \"measurement_8\"],\n","        \"B\": [\"measurement_4\", \"measurement_5\", \"measurement_7\"],\n","        \"C\": [\"measurement_5\", \"measurement_7\", \"measurement_8\", \"measurement_9\"],\n","        \"D\": [\"measurement_5\", \"measurement_6\", \"measurement_7\", \"measurement_8\"],\n","        \"E\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_8\"],\n","        \"F\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_7\"],\n","        \"G\": [\"measurement_4\", \"measurement_6\", \"measurement_8\", \"measurement_9\"],\n","        \"H\": [\"measurement_4\",\"measurement_5\",\"measurement_7\",\"measurement_8\",\"measurement_9\"],\n","        \"I\": [\"measurement_3\", \"measurement_7\", \"measurement_8\"],\n","    }\n","\n","    col = [col for col in df_test.columns if \"measurement\" not in col] + [\"loading\",\"m3_missing\",\"m5_missing\",]\n","    a = []\n","    b = []\n","    for x in range(3, 17):\n","        corr = np.absolute(data.drop(col, axis=1).corr()[f\"measurement_{x}\"]).sort_values(ascending=False)\n","        a.append(np.round(np.sum(corr[1:4]), 3))  \n","        b.append(f\"measurement_{x}\")\n","    c = pd.DataFrame()\n","    c[\"Selected columns\"] = b\n","    c[\"correlation total\"] = a\n","    c = c.sort_values(by=\"correlation total\", ascending=False).reset_index(drop=True)\n","    #print(c.head(10))\n","\n","    for i in range(10):\n","        m_col = (\"measurement_\" + c.iloc[i, 0][12:])  \n","        fill_dict = {}\n","        for x in data.product_code.unique():\n","            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[m_col]).sort_values(ascending=False)\n","            #print(corr)\n","            m_col_dic = {}\n","            m_col_dic[m_col] = corr[1:5].index.tolist()\n","            fill_dict[x] = m_col_dic[m_col]\n","        full[m_col] = fill_dict\n","    feature = [f for f in data.columns if f.startswith(\"measurement\") or f == \"loading\"]\n","    n_col = [col for col in df_train.columns if df_train[col].isnull().sum() != 0]\n","    for code in data.product_code.unique():\n","        for m_col in list(full.keys()):\n","            tmp = data[data.product_code == code]\n","            column = full[m_col][code]\n","            ttrain = tmp[column + [m_col]].dropna(how=\"any\")\n","            #print(tmp_train)\n","            ttest = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp[m_col].isnull())]\n","            #print(tmp_test)\n","            model = HuberRegressor(epsilon=1.9,max_iter=3000)\n","            model.fit(ttrain[column], ttrain[m_col])\n","            data.loc[(data.product_code == code) & (data[column].isnull().sum(axis=1) == 0)& (data[m_col].isnull()),m_col,] = model.predict(ttest[column])\n","\n","        NA = data.loc[data[\"product_code\"] == code, n_col].isnull().sum().sum()\n","        model1 = KNNImputer(n_neighbors=3)\n","        data.loc[data.product_code == code, feature] = model1.fit_transform(data.loc[data.product_code == code, feature])\n","\n","    data[\"measurement_avg\"] = data[[f\"measurement_{i}\" for i in range(3, 17)]].mean(axis=1)\n","    df_train = data.iloc[: df_train.shape[0], :]\n","    df_test = data.iloc[df_train.shape[0] :, :]\n","    #print(data)\n","    #print(df_train)\n","    #print(df_test)\n","    woe_encoder = WoEEncoder(variables=[\"attribute_0\"])\n","    woe_encoder.fit(df_train, target)\n","    df_train = woe_encoder.transform(df_train)\n","    df_test = woe_encoder.transform(df_test)\n","    features = [\"loading\",\"attribute_0\",\"measurement_17\",\"measurement_0\",\"measurement_1\",\"measurement_2\",\"m3_missing\",\"m5_missing\",\"measurement_avg\"]\n","    return df_train, df_test, features\n","\n","train, test, FEATURES = preprocessing(train, test)\n","train[\"failure\"] = target"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">3 vs 2 fold</h1>\n","</div>"]},{"cell_type":"code","execution_count":184,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:46.631153Z","iopub.status.busy":"2023-01-09T16:28:46.630935Z","iopub.status.idle":"2023-01-09T16:28:49.504837Z","shell.execute_reply":"2023-01-09T16:28:49.503966Z","shell.execute_reply.started":"2023-01-09T16:28:46.631132Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["##### Fold 1 #####\n","0.590424659643622\n","##### Fold 2 #####\n","0.5870302712565572\n","##### Fold 3 #####\n","0.5952351775082422\n","##### Fold 4 #####\n","0.5870248450994079\n","##### Fold 5 #####\n","0.5891103224632019\n","##### Fold 6 #####\n","0.5890572383753485\n","##### Fold 7 #####\n","0.5858906328885832\n","##### Fold 8 #####\n","0.5899624327668974\n","##### Fold 9 #####\n","0.5843865344046771\n","##### Fold 10 #####\n","0.5958328959652958\n"]}],"source":["#===============training===============#\n","def train_model(df,test,FEATURES,TARGET):\n","    final_test_predictions = []\n","    test = test[FEATURES].copy()\n","\n","    folds_dict = {f'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n","               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n","               'Fold 3': [['A', 'C', 'E'], ['B', 'D']],\n","               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n","               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n","               'Fold 6': [['A', 'B', 'C'], ['D', 'E']],\n","               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n","               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n","               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n","               'Fold 10': [['B', 'C', 'E'], ['A', 'D']]} \n","   \n","    for fold in folds_dict.keys():\n","        print(f'##### {fold} #####')\n","        xtest = test.copy()\n","        #print(df)\n","        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n","        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n","        #print(xtrain)\n","        model = LogisticRegression(max_iter=200, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n","        model.fit(xtrain,ytrain)\n","        preds_valid = model.predict_proba(xvalid)[:, 1]\n","        test_preds = model.predict_proba(xtest.values)[:, 1]\n","        #print(test_preds)\n","        #final_test_predictions.append(test_preds)\n","        fold_score = roc_auc_score(yvalid, preds_valid)  \n","        print(fold_score)\n","    #final_test_predictions.append(test_preds)\n","    return (model,final_test_predictions)\n","\n","#print(train)\n","filename = 'model1.sav'\n","\n","(model,final_test_preds) = train_model(train,test,FEATURES,TARGET)\n","pickle.dump(model, open(filename, 'wb'))\n","#final_test_preds.append(model.predict_proba(test[FEATURES].values)[:, 1])\n"]},{"cell_type":"code","execution_count":185,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:49.506741Z","iopub.status.busy":"2023-01-09T16:28:49.506192Z","iopub.status.idle":"2023-01-09T16:28:49.513731Z","shell.execute_reply":"2023-01-09T16:28:49.512969Z","shell.execute_reply.started":"2023-01-09T16:28:49.506707Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'submission_df = test[[\"id\"]].copy().astype(int)\\nsubmission_df[TARGET] = np.mean(np.column_stack(final_test_preds), axis=1)\\nsubmission_df.to_csv(\"109550116submission.csv\", index=False)'"]},"execution_count":185,"metadata":{},"output_type":"execute_result"}],"source":["#===============submission===============#\n","'''submission_df = test[[\"id\"]].copy().astype(int)\n","submission_df[TARGET] = np.mean(np.column_stack(final_test_preds), axis=1)\n","submission_df.to_csv(\"109550116submission.csv\", index=False)'''"]},{"cell_type":"markdown","metadata":{},"source":[" \n","<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">K-fold</h1>\n","</div>\n"," "]},{"cell_type":"code","execution_count":186,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:49.519250Z","iopub.status.busy":"2023-01-09T16:28:49.516773Z","iopub.status.idle":"2023-01-09T16:28:51.185517Z","shell.execute_reply":"2023-01-09T16:28:51.184788Z","shell.execute_reply.started":"2023-01-09T16:28:49.519219Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["##### Fold 1 #####\n","0.5916299060845487\n","##### Fold 2 #####\n","0.5988509442446043\n","##### Fold 3 #####\n","0.5819009833717517\n","##### Fold 4 #####\n","0.5852605096575232\n","##### Fold 5 #####\n","0.5924883658160595\n"]}],"source":["#===============training===============#\n","def train_model1(df,test,FEATURES,TARGET):\n","    final_test_predictions = []\n","    test = test[FEATURES].copy()\n","\n","    folds_dict = {f'Fold 1': [['B','C', 'D', 'E'], ['A']], \n","               'Fold 2': [['A','B','D', 'E'], ['D']],\n","               'Fold 3': [['A','B','C', 'D'], ['E']],\n","               'Fold 4': [['A', 'B','D','E'], ['C']],\n","               'Fold 5': [['A', 'D', 'C','E'], ['B']]} \n","   \n","    for fold in folds_dict.keys():\n","        print(f'##### {fold} #####')\n","        xtest = test.copy()\n","        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n","        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n","        #print(xtrain)\n","        model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n","        model.fit(xtrain,ytrain)\n","        preds_valid = model.predict_proba(xvalid)[:, 1]\n","        test_preds = model.predict_proba(xtest.values)[:, 1]\n","        #print(test_preds)\n","        final_test_predictions.append(test_preds)\n","        fold_score = roc_auc_score(yvalid, preds_valid)  \n","        print(fold_score)\n","    return (model)\n","\n","#print(train)\n","\n","filename = 'model2.sav'\n","\n","(model_kfold) = train_model1(train,test,FEATURES,TARGET)\n","pickle.dump(model_kfold, open(filename, 'wb'))\n","#final_test_preds1.append(model_kfold.predict_proba(test[FEATURES].values)[:, 1])\n"]},{"cell_type":"code","execution_count":187,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:51.188906Z","iopub.status.busy":"2023-01-09T16:28:51.188039Z","iopub.status.idle":"2023-01-09T16:28:51.193938Z","shell.execute_reply":"2023-01-09T16:28:51.193267Z","shell.execute_reply.started":"2023-01-09T16:28:51.188876Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'submission_kfold_df = test[[\"id\"]].copy().astype(int)\\nsubmission_kfold_df[TARGET] = np.mean(np.column_stack(final_test_preds1), axis=1)\\nsubmission_kfold_df.to_csv(\"109550116submission_kfold.csv\", index=False)'"]},"execution_count":187,"metadata":{},"output_type":"execute_result"}],"source":["#===============submission===============#\n","'''submission_kfold_df = test[[\"id\"]].copy().astype(int)\n","submission_kfold_df[TARGET] = np.mean(np.column_stack(final_test_preds1), axis=1)\n","submission_kfold_df.to_csv(\"109550116submission_kfold.csv\", index=False)'''"]},{"cell_type":"markdown","metadata":{},"source":["<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">No-fold</h1>\n","</div>"]},{"cell_type":"code","execution_count":188,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:51.195782Z","iopub.status.busy":"2023-01-09T16:28:51.195268Z","iopub.status.idle":"2023-01-09T16:28:51.528287Z","shell.execute_reply":"2023-01-09T16:28:51.527575Z","shell.execute_reply.started":"2023-01-09T16:28:51.195754Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.5942057929074573\n"]}],"source":["#===============training===============#\n","def train_model2(df,test,FEATURES,TARGET):\n","    final_test_predictions = []\n","    test = test[FEATURES].copy()\n","\n","    \n","    #print(f'########################## {fold} ##########################')\n","    xtest = test.copy()\n","    \n","    xtrain, xvalid = train_test_split(df, random_state=777, train_size=0.8)\n","    #print(xtrain)\n","    ytrain = xtrain[TARGET]\n","    #print(ytrain)\n","    yvalid = xvalid[TARGET]\n","    xtrain = xtrain[FEATURES]\n","    xvalid = xvalid[FEATURES]\n","    \n","    model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n","    model.fit(xtrain,ytrain)\n","    preds_valid = model.predict_proba(xvalid)[:, 1]\n","    test_preds = model.predict_proba(xtest.values)[:, 1]\n","    #print(test_preds)\n","    final_test_predictions.append(test_preds)\n","    fold_score = roc_auc_score(yvalid, preds_valid)  \n","    print(fold_score)\n","    return (model,final_test_predictions)\n","\n","#print(train)\n","#(model_no_fold,final_test_preds2) = train_model(train,test,FEATURES,TARGET)\n","\n","filename = 'model3.sav'\n","\n","(model_no_fold,final_test_preds2) = train_model2(train,test,FEATURES,TARGET)\n","pickle.dump(model_no_fold, open(filename, 'wb'))\n","#final_test_preds2.append(model_no_fold.predict_proba(test[FEATURES].values)[:, 1])"]},{"cell_type":"code","execution_count":189,"metadata":{"execution":{"iopub.execute_input":"2023-01-09T16:28:51.530114Z","iopub.status.busy":"2023-01-09T16:28:51.529618Z","iopub.status.idle":"2023-01-09T16:28:51.535103Z","shell.execute_reply":"2023-01-09T16:28:51.534410Z","shell.execute_reply.started":"2023-01-09T16:28:51.530086Z"},"trusted":true},"outputs":[{"data":{"text/plain":["'submission_no_fold_df = test[[\"id\"]].copy().astype(int)\\nsubmission_no_fold_df[TARGET] = np.mean(np.column_stack(final_test_preds2), axis=1)\\nsubmission_no_fold_df.to_csv(\"109550116submission_no_fold.csv\", index=False)'"]},"execution_count":189,"metadata":{},"output_type":"execute_result"}],"source":["#===============submission===============#\n","'''submission_no_fold_df = test[[\"id\"]].copy().astype(int)\n","submission_no_fold_df[TARGET] = np.mean(np.column_stack(final_test_preds2), axis=1)\n","submission_no_fold_df.to_csv(\"109550116submission_no_fold.csv\", index=False)'''"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
