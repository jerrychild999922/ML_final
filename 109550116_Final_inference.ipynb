{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-01-09T16:30:47.186279Z","iopub.execute_input":"2023-01-09T16:30:47.186858Z","iopub.status.idle":"2023-01-09T16:30:47.196538Z","shell.execute_reply.started":"2023-01-09T16:30:47.186823Z","shell.execute_reply":"2023-01-09T16:30:47.195353Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"/kaggle/input/tabular-playground-series-aug-2022/sample_submission.csv\n/kaggle/input/tabular-playground-series-aug-2022/train.csv\n/kaggle/input/tabular-playground-series-aug-2022/test.csv\n/kaggle/input/pickle/model3.sav\n/kaggle/input/pickle/model1.sav\n/kaggle/input/pickle/model2.sav\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!pip install feature-engine","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:30:47.198264Z","iopub.execute_input":"2023-01-09T16:30:47.198632Z","iopub.status.idle":"2023-01-09T16:30:58.321065Z","shell.execute_reply.started":"2023-01-09T16:30:47.198596Z","shell.execute_reply":"2023-01-09T16:30:58.319464Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!rm 109550116submission.csv 109550116submission_no_fold.csv 109550116submission_kfold.csv","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:30:58.323144Z","iopub.execute_input":"2023-01-09T16:30:58.323942Z","iopub.status.idle":"2023-01-09T16:30:59.415324Z","shell.execute_reply.started":"2023-01-09T16:30:58.323871Z","shell.execute_reply":"2023-01-09T16:30:59.413459Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"#===============import===============#\nimport os\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport pickle\nfrom sklearn.linear_model import LogisticRegression ,HuberRegressor\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.impute import KNNImputer\nfrom feature_engine.encoding import WoEEncoder\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\nTARGET = \"failure\"\n#usepickle=0","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:30:59.418124Z","iopub.execute_input":"2023-01-09T16:30:59.418636Z","iopub.status.idle":"2023-01-09T16:30:59.426300Z","shell.execute_reply.started":"2023-01-09T16:30:59.418585Z","shell.execute_reply":"2023-01-09T16:30:59.425094Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#===============load data===============#\ndef read(path):\n    data_dir = Path(path)\n    train = pd.read_csv(data_dir / \"train.csv\")\n    test = pd.read_csv(data_dir / \"test.csv\")\n    return train, test\n\ntrain, test = read(\"../input/tabular-playground-series-aug-2022\")\ntarget = train[\"failure\"]\ntrain.drop(\"failure\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:30:59.427549Z","iopub.execute_input":"2023-01-09T16:30:59.428464Z","iopub.status.idle":"2023-01-09T16:30:59.620014Z","shell.execute_reply.started":"2023-01-09T16:30:59.428430Z","shell.execute_reply":"2023-01-09T16:30:59.618924Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"#===============preprocessing===============#\ndef preprocessing(df_train, df_test):\n    data = pd.concat([df_train, df_test])\n    data[\"m3_missing\"] = data[\"measurement_3\"].isnull().astype(np.int8)\n    data[\"m5_missing\"] = data[\"measurement_5\"].isnull().astype(np.int8)\n    feature = [f for f in df_test.columns if f.startswith(\"measurement\") or f == \"loading\"]\n\n    full = {}\n    full[\"measurement_17\"] = {\n        \"A\": [\"measurement_5\", \"measurement_6\", \"measurement_8\"],\n        \"B\": [\"measurement_4\", \"measurement_5\", \"measurement_7\"],\n        \"C\": [\"measurement_5\", \"measurement_7\", \"measurement_8\", \"measurement_9\"],\n        \"D\": [\"measurement_5\", \"measurement_6\", \"measurement_7\", \"measurement_8\"],\n        \"E\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_8\"],\n        \"F\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_7\"],\n        \"G\": [\"measurement_4\", \"measurement_6\", \"measurement_8\", \"measurement_9\"],\n        \"H\": [\"measurement_4\",\"measurement_5\",\"measurement_7\",\"measurement_8\",\"measurement_9\"],\n        \"I\": [\"measurement_3\", \"measurement_7\", \"measurement_8\"],\n    }\n\n    col = [col for col in df_test.columns if \"measurement\" not in col] + [\"loading\",\"m3_missing\",\"m5_missing\",]\n    a = []\n    b = []\n    for x in range(3, 17):\n        corr = np.absolute(data.drop(col, axis=1).corr()[f\"measurement_{x}\"]).sort_values(ascending=False)\n        a.append(np.round(np.sum(corr[1:4]), 3))  \n        b.append(f\"measurement_{x}\")\n    c = pd.DataFrame()\n    c[\"Selected columns\"] = b\n    c[\"correlation total\"] = a\n    c = c.sort_values(by=\"correlation total\", ascending=False).reset_index(drop=True)\n    #print(c.head(10))\n\n    for i in range(10):\n        m_col = (\"measurement_\" + c.iloc[i, 0][12:])  \n        fill_dict = {}\n        for x in data.product_code.unique():\n            corr = np.absolute(data[data.product_code == x].drop(col, axis=1).corr()[m_col]).sort_values(ascending=False)\n            #print(corr)\n            m_col_dic = {}\n            m_col_dic[m_col] = corr[1:5].index.tolist()\n            fill_dict[x] = m_col_dic[m_col]\n        full[m_col] = fill_dict\n    feature = [f for f in data.columns if f.startswith(\"measurement\") or f == \"loading\"]\n    n_col = [col for col in df_train.columns if df_train[col].isnull().sum() != 0]\n    for code in data.product_code.unique():\n        for m_col in list(full.keys()):\n            tmp = data[data.product_code == code]\n            column = full[m_col][code]\n            ttrain = tmp[column + [m_col]].dropna(how=\"any\")\n            #print(tmp_train)\n            ttest = tmp[(tmp[column].isnull().sum(axis=1) == 0) & (tmp[m_col].isnull())]\n            #print(tmp_test)\n            model = HuberRegressor(epsilon=1.9,max_iter=3000)\n            model.fit(ttrain[column], ttrain[m_col])\n            data.loc[(data.product_code == code) & (data[column].isnull().sum(axis=1) == 0)& (data[m_col].isnull()),m_col,] = model.predict(ttest[column])\n\n        NA = data.loc[data[\"product_code\"] == code, n_col].isnull().sum().sum()\n        model1 = KNNImputer(n_neighbors=3)\n        data.loc[data.product_code == code, feature] = model1.fit_transform(data.loc[data.product_code == code, feature])\n\n    data[\"measurement_avg\"] = data[[f\"measurement_{i}\" for i in range(3, 17)]].mean(axis=1)\n    df_train = data.iloc[: df_train.shape[0], :]\n    df_test = data.iloc[df_train.shape[0] :, :]\n    #print(data)\n    #print(df_train)\n    #print(df_test)\n    woe_encoder = WoEEncoder(variables=[\"attribute_0\"])\n    woe_encoder.fit(df_train, target)\n    df_train = woe_encoder.transform(df_train)\n    df_test = woe_encoder.transform(df_test)\n    features = [\"loading\",\"attribute_0\",\"measurement_17\",\"measurement_0\",\"measurement_1\",\"measurement_2\",\"m3_missing\",\"m5_missing\",\"measurement_avg\"]\n    return df_train, df_test, features\n\ntrain, test, FEATURES = preprocessing(train, test)\ntrain[\"failure\"] = target","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:30:59.621974Z","iopub.execute_input":"2023-01-09T16:30:59.622315Z","iopub.status.idle":"2023-01-09T16:31:21.974333Z","shell.execute_reply.started":"2023-01-09T16:30:59.622285Z","shell.execute_reply":"2023-01-09T16:31:21.973037Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">3 vs 2 fold</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"#===============training===============#\n'''def train_model(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    folds_dict = {f'Fold 1': [['C', 'D', 'E'], ['A', 'B']], \n               'Fold 2': [['B', 'D', 'E'], ['A', 'C']],\n               'Fold 3': [['B', 'C', 'E'], ['A', 'D']],\n               'Fold 4': [['B', 'C', 'D'], ['A', 'E']],\n               'Fold 5': [['A', 'D', 'E'], ['B', 'C']],\n               'Fold 6': [['A', 'C', 'E'], ['B', 'D']],\n               'Fold 7': [['A', 'C', 'D'], ['B', 'E']],\n               'Fold 8': [['A', 'B', 'E'], ['C', 'D']],\n               'Fold 9': [['A', 'B', 'D'], ['C', 'E']],\n               'Fold 10': [['A', 'B', 'C'], ['D', 'E']]} \n   \n    for fold in folds_dict.keys():\n        print(f'##### {fold} #####')\n        xtest = test.copy()\n        #print(df)\n        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n        #print(xtrain)\n        model = LogisticRegression(max_iter=200, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n        model.fit(xtrain,ytrain)\n        preds_valid = model.predict_proba(xvalid)[:, 1]\n        test_preds = model.predict_proba(xtest.values)[:, 1]\n        #print(test_preds)\n        final_test_predictions.append(test_preds)\n        fold_score = roc_auc_score(yvalid, preds_valid)  \n        print(fold_score)\n    return (model,final_test_predictions)\n\n#print(train)\nfilename = 'model1.sav'\nif(usepickle==0):\n    (model,final_test_preds) = train_model(train,test,FEATURES,TARGET)\n    pickle.dump(model, open(filename, 'wb'))\n    #final_test_preds.append(model.predict_proba(test[FEATURES].values)[:, 1])'''\nfinal_test_preds=[]\nfilename = '/kaggle/input/pickle/model1.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\nfinal_test_preds.append(loaded_model.predict_proba(test[FEATURES].values)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:21.976347Z","iopub.execute_input":"2023-01-09T16:31:21.976814Z","iopub.status.idle":"2023-01-09T16:31:21.994591Z","shell.execute_reply.started":"2023-01-09T16:31:21.976770Z","shell.execute_reply":"2023-01-09T16:31:21.992615Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_df = test[[\"id\"]].copy().astype(int)\nsubmission_df[TARGET] = np.mean(np.column_stack(final_test_preds), axis=1)\nsubmission_df.to_csv(\"109550116submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:21.997180Z","iopub.execute_input":"2023-01-09T16:31:21.998354Z","iopub.status.idle":"2023-01-09T16:31:22.122199Z","shell.execute_reply.started":"2023-01-09T16:31:21.998281Z","shell.execute_reply":"2023-01-09T16:31:22.120943Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":" \n<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">K-fold</h1>\n</div>\n ","metadata":{}},{"cell_type":"code","source":"#===============training===============#\n'''def train_model1(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    folds_dict = {f'Fold 1': [['B','C', 'D', 'E'], ['A']], \n               'Fold 2': [['A','C','D', 'E'], ['B']],\n               'Fold 3': [['A','B','C', 'E'], ['D']],\n               'Fold 4': [['A', 'B','D','E'], ['C']],\n               'Fold 5': [['A', 'B', 'C','D'], ['E']]} \n   \n    for fold in folds_dict.keys():\n        print(f'##### {fold} #####')\n        xtest = test.copy()\n        xtrain, ytrain = df[df['product_code'].isin(folds_dict[fold][0])][FEATURES].values, df[df['product_code'].isin(folds_dict[fold][0])][TARGET].values\n        xvalid, yvalid = df[df['product_code'].isin(folds_dict[fold][1])][FEATURES].values,  df[df['product_code'].isin(folds_dict[fold][1])][TARGET].values\n        #print(xtrain)\n        model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n        model.fit(xtrain,ytrain)\n        preds_valid = model.predict_proba(xvalid)[:, 1]\n        test_preds = model.predict_proba(xtest.values)[:, 1]\n        #print(test_preds)\n        final_test_predictions.append(test_preds)\n        fold_score = roc_auc_score(yvalid, preds_valid)  \n        print(fold_score)\n    return (model)\n\n#print(train)\n\nfilename = 'model2.sav'\nif(usepickle==0):\n    (model_kfold) = train_model1(train,test,FEATURES,TARGET)\n    pickle.dump(model_kfold, open(filename, 'wb'))\n    #final_test_preds1.append(model_kfold.predict_proba(test[FEATURES].values)[:, 1])'''\nfinal_test_preds1=[]\nfilename = '/kaggle/input/pickle/model2.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\nfinal_test_preds1.append(loaded_model.predict_proba(test[FEATURES].values)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:22.123752Z","iopub.execute_input":"2023-01-09T16:31:22.124125Z","iopub.status.idle":"2023-01-09T16:31:22.134552Z","shell.execute_reply.started":"2023-01-09T16:31:22.124067Z","shell.execute_reply":"2023-01-09T16:31:22.133325Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_kfold_df = test[[\"id\"]].copy().astype(int)\nsubmission_kfold_df[TARGET] = np.mean(np.column_stack(final_test_preds1), axis=1)\nsubmission_kfold_df.to_csv(\"109550116submission_kfold.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:22.136481Z","iopub.execute_input":"2023-01-09T16:31:22.137782Z","iopub.status.idle":"2023-01-09T16:31:22.265449Z","shell.execute_reply.started":"2023-01-09T16:31:22.137714Z","shell.execute_reply":"2023-01-09T16:31:22.264196Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"background-color:rgba(255, 0, 100, 0.6);border-radius:5px;display:fill\"><h1 style=\"text-align: center;padding: 12px 0px 12px 0px;\">No-fold</h1>\n</div>","metadata":{}},{"cell_type":"code","source":"#===============training===============#\n'''def train_model2(df,test,FEATURES,TARGET):\n    final_test_predictions = []\n    test = test[FEATURES].copy()\n\n    \n    #print(f'########################## {fold} ##########################')\n    xtest = test.copy()\n    \n    xtrain, xvalid = train_test_split(df, random_state=777, train_size=0.8)\n    #print(xtrain)\n    ytrain = xtrain[TARGET]\n    #print(ytrain)\n    yvalid = xvalid[TARGET]\n    xtrain = xtrain[FEATURES]\n    xvalid = xvalid[FEATURES]\n    \n    model = LogisticRegression(max_iter=1000, C=0.0001, penalty=\"l2\", solver=\"newton-cg\")\n    model.fit(xtrain,ytrain)\n    preds_valid = model.predict_proba(xvalid)[:, 1]\n    test_preds = model.predict_proba(xtest.values)[:, 1]\n    #print(test_preds)\n    final_test_predictions.append(test_preds)\n    fold_score = roc_auc_score(yvalid, preds_valid)  \n    print(fold_score)\n    return (model,final_test_predictions)\n\n#print(train)\n#(model_no_fold,final_test_preds2) = train_model(train,test,FEATURES,TARGET)\n\nfilename = 'model3.sav'\nif(usepickle==0):\n    (model_no_fold,final_test_preds2) = train_model2(train,test,FEATURES,TARGET)\n    pickle.dump(model_no_fold, open(filename, 'wb'))'''\nfinal_test_preds2=[]\nfilename = '/kaggle/input/pickle/model3.sav'\nloaded_model = pickle.load(open(filename, 'rb'))\nfinal_test_preds2.append(loaded_model.predict_proba(test[FEATURES].values)[:, 1])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:22.267083Z","iopub.execute_input":"2023-01-09T16:31:22.267434Z","iopub.status.idle":"2023-01-09T16:31:22.278611Z","shell.execute_reply.started":"2023-01-09T16:31:22.267403Z","shell.execute_reply":"2023-01-09T16:31:22.277116Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"#===============submission===============#\nsubmission_no_fold_df = test[[\"id\"]].copy().astype(int)\nsubmission_no_fold_df[TARGET] = np.mean(np.column_stack(final_test_preds2), axis=1)\nsubmission_no_fold_df.to_csv(\"109550116submission_no_fold.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T16:31:22.281363Z","iopub.execute_input":"2023-01-09T16:31:22.281974Z","iopub.status.idle":"2023-01-09T16:31:22.407491Z","shell.execute_reply.started":"2023-01-09T16:31:22.281925Z","shell.execute_reply":"2023-01-09T16:31:22.406310Z"},"trusted":true},"execution_count":47,"outputs":[]}]}